import json
import re
from typing import Any, Dict, List
from pydantic import ValidationError
import logging
from starlette.concurrency import run_in_threadpool

from backend.llm_client import get_llm_response
from backend.tools import get_tool_definitions, execute_tool
from backend.database import save_chat_history
from backend.schemas import PlanModel, StepModel
from backend.memory_manager import memory_manager
from backend.config import settings
from backend.lucidus.verification import verify_code

logger = logging.getLogger("agent_core")

# --- META-PLANNER FUNCTION (The "Strategist") ---
async def run_meta_planner(user_prompt: str, correlation_id: str) -> List[Dict[str, Any]]:
    """
    Takes a high-level user goal and decomposes it into a list of
    smaller, concrete tasks for the execution agent.
    """
    logger.info(f"Meta-Planner engaged for high-level goal: '{user_prompt[:100]}...'")

    meta_planner_system_prompt = (
        "You are a world-class AI project manager. Your sole responsibility is to take a complex user request and break it down into a numbered list of simple, concrete, single-action tasks that a junior developer can execute. "
        "Do NOT generate code. Do NOT generate JSON. Do NOT solve the tasks yourself. "
        "Your ONLY output should be a numbered list of tasks, with each task on a new line.\n\n"
        "**CRITICAL RULE FOR PYTHON PROJECTS:** When setting up a new Python project, you must first create a virtual environment (e.g., `python3 -m venv venv`). "
        "For all subsequent steps, you MUST call executables from within that environment directly (e.g., `venv/bin/pip install <package>` or `venv/bin/python <script.py>`). "
        "Do NOT use the `source` command (e.g., `source venv/bin/activate`), as it will not work.\n\n"
        "**CRITICAL RULE FOR GIT:** When cloning a repository, you MUST use the SSH URL format. If the user provides an HTTPS URL like `https://github.com/user/repo.git`, you MUST convert it to the SSH format `git@github.com:user/repo.git` for the plan.\n\n"
        "**CRITICAL RULE ON WORKING DIRECTORIES:** The `execute_shell` tool is stateless. After cloning a repository into a sub-directory like `my-repo`, ALL subsequent `execute_shell` commands that should run inside that repository (like `git add`, `git commit`, `pip install`, `ls`) MUST include the `\"working_dir\": \"my-repo\"` parameter."
    )

    messages = [
        {"role": "system", "content": meta_planner_system_prompt},
        {"role": "user", "content": user_prompt}
    ]

    response_str = await get_llm_response(
        provider="mistral", model_name="mistral-large-latest", messages=messages,
        temperature=0.0, top_p=1.0, max_tokens=2048
    )

    tasks = re.findall(r'^\s*\d+\.\s*(.*)', response_str, re.MULTILINE)
    if not tasks:
        logger.warning("Meta-Planner did not produce a numbered list. Treating response as a single task.")
        return [{"tool": {"name": "execute_script", "parameters": {"command": response_str}},
                "reason": "Single task generated by Meta-Planner."}]

    logger.info(f"Meta-Planner decomposed goal into {len(tasks)} tasks.")

    # Convert tasks to the expected structure
    structured_tasks = []
    for task in tasks:
        structured_tasks.append({
            "tool": {"name": "execute_script", "parameters": {"command": task}},
            "reason": task
        })

    return structured_tasks

# --- HELPER FUNCTIONS FOR EXECUTION AGENT ---
def parse_json_from_response(response_str: str) -> Any:
    """Finds the first '{' and the last '}' and parses everything in between."""
    try:
        first_brace = response_str.find('{')
        last_brace = response_str.rfind('}')
        if first_brace != -1 and last_brace != -1:
            json_str = response_str[first_brace:last_brace+1]
            return json.loads(json_str)
        else:
            return {"content": response_str}
    except (json.JSONDecodeError, TypeError):
        return {"content": response_str}

def substitute_placeholders(parameters: Dict[str, Any], results: Dict[int, Any]) -> Dict[str, Any]:
    """Substitutes placeholders in a tool's parameter dictionary."""
    if not isinstance(parameters, dict):
        return parameters
    output_params = parameters.copy()
    for key, value in output_params.items():
        if isinstance(value, str):
            placeholder_pattern = r"<ref:step_(\d+)_result>|{{\s*step_(\d+)_result\s*}}"
            def replace_match(match):
                step_index_str = match.group(1) or match.group(2)
                step_index = int(step_index_str)
                if step_index in results:
                    return str(results[step_index].get("data", ""))
                return match.group(0)
            output_params[key] = re.sub(placeholder_pattern, replace_match, value)
    return output_params

def plan_sanity_check(plan: List[StepModel], user_prompt: str) -> (bool, str):
    """Verifies that filenames (including paths) used in the plan were mentioned in the user prompt."""
    prompt_filenames = set(re.findall(r'[`"]?([\w\.\-\_\/]+?\.(?:py|json|txt|md|sh|yaml|yml))[`"]?', user_prompt))
    if not prompt_filenames:
        return True, ""
    for step in plan:
        if step.parameters and "filename" in step.parameters:
            plan_filename = step.parameters["filename"]
            if plan_filename not in prompt_filenames:
                error_msg = (f"Plan validation failed: Agent hallucinated filename '{plan_filename}' "
                             f"which was not in the user prompt. Mentioned files were: {list(prompt_filenames)}")
                logger.error(error_msg)
                return False, error_msg
    return True, ""

async def validate_plan_semantically(plan_list: List[Dict[str, Any]], user_prompt: str, correlation_id: str) -> (bool, str, List[Dict[str, Any]]):
    """Uses an LLM to check if a plan is logically sound."""
    logger.info("Engaging Plan Critic for semantic validation.")
    critic_system_prompt = (
        "You are a Senior AI Architect acting as a 'Plan Critic'. Your task is to evaluate a JSON plan created by another AI. Your focus is on LOGIC and EFFICIENCY.\n\n"
        "1. Analyze the user's goal and the provided plan.\n"
        "2. Check for logical errors, such as trying to read a file before it's created.\n"
        "3. If the plan is logical and sound, your ONLY response must be the word: OK\n"
        "4. If the plan is flawed, you MUST respond with ONLY a corrected JSON plan object. Your corrected plan MUST be complete and include the 'tool', 'parameters', and 'reason' keys for every step."
    )
    plan_str = json.dumps({"plan": plan_list}, indent=2)
    critic_user_prompt = f"User Goal: \"{user_prompt}\"\n\nGenerated Plan:\n{plan_str}"
    messages = [{"role": "system", "content": critic_system_prompt}, {"role": "user", "content": critic_user_prompt}]

    response_str = await get_llm_response(
        provider="mistral", model_name="mistral-large-latest", messages=messages, temperature=0.0
    )
    if response_str.strip() == "OK":
        logger.info("Plan Critic approved the plan.")
        return True, "Plan is logically sound.", plan_list
    else:
        logger.warning("Plan Critic detected a flaw and provided a correction.")
        try:
            corrected_plan_data = parse_json_from_response(response_str)
            if "plan" in corrected_plan_data:
                PlanModel(**corrected_plan_data)
                return True, "Plan was corrected by Critic.", corrected_plan_data['plan']
            else: return False, "Critic provided an invalid correction format.", plan_list
        except (ValidationError, json.JSONDecodeError) as e:
            logger.error(f"Critic's corrected plan was invalid: {e}")
            return False, f"Critic's corrected plan was invalid: {e}", plan_list

# --- EXISTING EXECUTION AGENT (The "Tactician") ---
async def run_agent(
    user_prompt: str, session_id: str, chat_history: list, correlation_id: str = "no-correlation-id"
) -> Dict[str, Any]:
    logger.info(f"Execution Agent starting task: '{user_prompt[:100]}...'")
    original_user_prompt = user_prompt
    full_history = list(chat_history)
    full_history.append({"role": "user", "content": original_user_prompt})
    max_retries = settings.max_retries
    execution_error = None

    for attempt in range(max_retries):
        if attempt > 0:
            user_prompt = (
                f"My original goal was: '{original_user_prompt}'.\n\n"
                f"My last plan failed with the following error:\n{execution_error}\n\n"
                "Please analyze the error and create a new, corrected plan to achieve my original goal. Do not repeat the mistake."
            )

        print("\n--- STAGE 0: MEMORY RETRIEVAL ---")
        retrieved_context_list = memory_manager.retrieve_from_memory(user_prompt)
        context_str = "\n\n---\n\n".join(retrieved_context_list)
        if context_str: logger.info("Injecting retrieved context.")
        else: logger.info("No relevant context found in memory.")

        print(f"\n--- STAGE 1: PLAN GENERATION (Attempt {attempt + 1}/{max_retries}) ---")
        tool_schemas_str = json.dumps(get_tool_definitions(), indent=2)

        # This is the final, most specific system prompt
        planning_system_prompt = (
            "You are a tactical AI agent. Your only job is to take a single, simple, concrete task and create a JSON plan to execute it using the available tools. "
            "Your output MUST be a JSON object with a 'plan' key.\n\n"
            "**CRITICAL RESPONSE FORMATTING:**\n"
            "1. Your output MUST be a single JSON object with a single root key named \"plan\".\n"
            "2. The value of \"plan\" MUST be a list of step objects.\n"
            "3. Each step object in the list MUST have EXACTLY three keys: \"tool\", \"parameters\", and \"reason\".\n"
            "4. **Each step must represent a single, atomic action.** Do NOT combine multiple commands into one step.\n"
            "5. The \"parameters\" for the \"execute_script\" tool must contain a single key named \"command\" whose value is a string.\n\n"
            "Example of a PERFECT response:\n"
            "{\n"
            '  "plan": [\n'
            '    {\n'
            '      "tool": {"name": "execute_script"},\n'
            '      "parameters": {"command": "echo \'hello world\'"},\n'
            '      "reason": "This is an example step to print hello world."\n'
            '    }\n'
            '  ]\n'
            '}\n\n'
            "### CONTEXT FROM LONG-TERM MEMORY ###\n"
            f"{context_str if context_str else 'No relevant context found.'}\n"
            "### END CONTEXT ###\n\n"
            "AVAILABLE TOOLS:\n"
            f"{tool_schemas_str}\n\n"
            "Now, create a plan for the user's simple request."
        )

        planning_messages = [{"role": "system", "content": planning_system_prompt}, {"role": "user", "content": user_prompt}]

        llm_plan_response_str = await get_llm_response(
            provider="mistral", model_name="mistral-large-latest", messages=planning_messages,
            temperature=0.0, top_p=1.0, max_tokens=4096
        )
        parsed_data = parse_json_from_response(llm_plan_response_str)
        print("--- RAW LLM JSON ---")
        print(parsed_data)
        if "content" in parsed_data:
            return {"response": parsed_data["content"], "full_history": full_history}

        # This is the new, corrected code block
        try:
            # First, try to validate the structure as is (e.g., {"plan": [...]})
            plan = PlanModel(**parsed_data).plan
        except ValidationError:
            try:
                # If that fails, assume the LLM gave a raw list and wrap it
                plan = PlanModel(plan=parsed_data).plan
            except ValidationError as e:
                # If both fail, then it's a real error
                logger.error(f"Pydantic validation failed on both attempts: {e}")
                return {"response": f"Invalid plan structure: {e}", "full_history": full_history}

        is_sane, sanity_error = plan_sanity_check(plan, user_prompt)
        if not is_sane:
            return {"response": sanity_error, "full_history": full_history}

        is_logical, comment, corrected_plan_list = await validate_plan_semantically(parsed_data['plan'], user_prompt, correlation_id)
        if not is_logical:
            return {"response": f"Semantic validation failed: {comment}", "full_history": full_history}

        plan = PlanModel(plan=corrected_plan_list).plan
        logger.info(f"Plan semantic validation: SUCCESS. {comment}")
        full_history.append({"role": "assistant", "content": f"Plan Generated (and validated): {comment}\n```json\n{json.dumps({'plan': corrected_plan_list}, indent=2)}\n```"})
        print(f"✅ Plan generated with {len(plan)} steps.")

        print("\n--- STAGE 2: EXECUTION ---")
        step_results = {}
        execution_error = None

        for i, step in enumerate(plan):
            print(f"Executing step {i+1}/{len(plan)}: {step.tool}")
            params = substitute_placeholders(step.parameters, step_results)
            tool_output = await execute_tool(step.tool, params, session_id, original_user_prompt)
            step_results[i] = tool_output
            print(f"🔭 Observed: {tool_output}")
            if tool_output.get("status") == "error":
                error_message = f"Execution stopped at step {i+1} ({step.tool}): {tool_output.get('message')}"
                full_history.append({"role": "assistant", "content": error_message})
                retryable_errors = ["not found", "does not exist"]
                is_retryable = any(keyword in error_message.lower() for keyword in retryable_errors)
                if is_retryable:
                    execution_error = error_message
                    break
                else:
                    logger.error(f"Execution failed with a non-retryable error. Halting.")
                    return {"response": error_message, "full_history": full_history}

        if not execution_error:
            print("\n--- STAGE 3: FINAL REPORT ---")
            final_result = step_results.get(len(plan) - 1, {})
            final_answer = final_result.get("data", "The plan has been executed successfully.")
            full_history.append({"role": "assistant", "content": str(final_answer)})
            return {"response": str(final_answer), "full_history": full_history}

    final_error_message = f"Agent failed after {max_retries} attempts. Last error: {execution_error}"
    full_history.append({"role": "assistant", "content": final_error_message})
    return {"response": final_error_message, "full_history": full_history}

